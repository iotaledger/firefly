[[{"l":"Home","p":["Welcome to the Firefly handbook!"]}],[{"l":"Guides","p":["Welcome to the Firefly handbook guides! Here you will find all of the information needed for Firefly app development \uD83D\uDD25"]}],[{"l":"Coding Conventions","p":["Welcome to the Firefly coding conventions guide! Here you will find all of the information regarding how we write our code."]}],[{"l":"Comments"},{"l":"Regular Comments","p":["Every time you express yourself in code, you should pat yourself on the back. Every time you write a comment, you should grimace and feel the failure of your ability of expression.","In general it is preferable to avoid writing comments, especially if there is a way to cleanly express the logic with the code itself(aka self-documenting code). Otherwise, we adhere to the following rules about comments:","Do NOT write comments that are noisy or state the obvious","Do NOT write TODO comments","ℹ️ If you find yourself writing TODO comments, instead create a new task on GitHub or add to your existing task's requirements list.","Do NOT write inline or embedded comments","Bad","Good","They should be preceded by a blank without a following a blank line"]},{"l":"TSDoc Comments","p":["Because our library is of a considerable size, it is helpful to create and maintain library specifications and documentation so that developers can easily see what is inside a particular module.","As such, it is important that when writing code that is intended to be used elsewhere(e.g. in a component, elsewhere in the library), it is annotated with a TSDoc comment. It is also important to write these comments consistently and in a way that makes it easier to actually read the generated markdown specification pages.","Helpers functions within a module file should NOT be annotated."]},{"l":"Constants","p":["When writing constants, use the following template:","Example"]},{"l":"Enums","p":["When writing enums, use the following template:","Example"]},{"l":"Functions"},{"i":"void--promisevoid","l":"void / Promisevoid","p":["When writing functions that returns void or Promisevoid, use the following template:","Example"]},{"l":"boolean","p":["When writing functions that return a boolean, use the following template:","Example"]},{"i":"non-voidpromisevoid-and-non-boolean","l":"Non-void/Promisevoid and non-boolean","p":["When writing functions that return neither void nor Promisevoid nor boolean s, use the following template:","Example"]},{"l":"Interfaces","p":["When writing interfaces, use the following template:","Example"]},{"l":"Types","p":["When writing types, use the following template:","Example"]},{"l":"Stores","p":["When writing stores, use the following template:","Example"]}],[{"l":"Components","p":["Component-related TypeScript code ( enums, interfaces, types, etc.) MUST live in the component file itself","Component names should be appended with the corresponding type of component, i.e. a “view” component should be named SomeComponentView(the filename should also match)","Props classes have to disappear. If we need to style a component, we can wrap up and apply the classes to the wrapper","Platform conditionals should be avoided at all times, and variations should be used instead."]},{"l":"Organization","p":["The organization of a Svelte component must start with the script, followed by the markup and the style.","Bad","Good"]},{"l":"Reactivity","p":["At the heart of Svelte is a powerful system of reactivity for keeping the DOM in sync with the application state — for example, in response to an event. This section describes our approach to throughout the codebase. Reactive stores (a language feature) assign a store value (app state) to a local variable, and thanks to Svelte reactivity all the markup and reactive dependencies are updated in Svelte Components.","It's not enforced, since regular typescript handles store variables differently. However, the following approach is preferred in Svelte components. Feel free to test the code on the Svelte Playground!","Preferred","The same code can be written without using Svelte language features. The following code does the same, albeit being a bit more verbose. This is how store interactions are written in pure typescript. It is accepted, but for Svelte components preference is given to the style described above.","Alternative"]},{"l":"Styling","p":["style attribute should only be used for variables style:--opacity={elementX / screenWidth}","Good","Bad","component with multiple variants: the preferred approach is a combination of classes and the style tag, vs creating a string composed of classes generated in TS","Preferred: CSS approach","Other: TS approach","If a component needs a style that is not inside the tailwind scope, the custom style should be added in the style CSS section","Max nested children = 1","The preferred way to add styles to a DOM element that does not have variants, is by adding tailwind classes in the class attribute","The preferred way to add styled to a DOM element that does have variants, is by adding tailwind classes in the style section","The same DOM element should not contain a combination of tailwind classes (in the class attribute) & CSS (in the style section), unless the required styling does not exist in tailwind","Custom HTML tags are preferred","When writing tailwind classes, string concatenation should be avoided because the tailwind purging process skips string concatenations"]},{"l":"Prettier","p":["There is a bug in Prettier's Svelte Plugin that replaces nested style and script tags with base58 encoded strings of vanilla JS. Use nested strings in case nested style/script tags are required.","Bad","Good"]}],[{"l":"Errors","p":["Our code takes a class-based approach to error handling, allowing us to write domain-specific errors and sometimes even with specific logic built in.","ℹ️ These errors can be thrown from any layer within the library as needed."]},{"l":"Error Parameters","p":["Each error extends the BaseError class, which, as a constructor argument, takes an object implementing the IErrorParameters interface:"]},{"l":"Creating an Error","p":["To create module- or domain-specific errors, you must write an additional class that extends the BaseError, e.g."]},{"l":"Using an Error","p":["To use one of these errors, it is simply a matter of throwing it like a normal Error, e.g."]},{"l":"Catching an Error","p":["To catch an error use the following syntax:"]},{"l":"Handling an Error","p":["To handle use the following syntax:","handleError() handles the error differently depending on if it is a:","wallet.rs error","ledger error","default: generic error"]},{"i":"errors-from-walletrs","l":"Errors from wallet.rs","p":["We handle errors from wallet.rs by using the handleError function, e.g.","This automatically checks, if the error comes from wallet.rs or not. Step-by-step the handlers for the corresponding errors (e.g. ClientError, InsufficientFunds, ...) are added to this function. If you encounter an unhandled error, create the handler and add the type and the corresponding handlers in the following position in the handleWalletRsError.ts:"]}],[{"l":"Formatting"},{"l":"Brackets","p":["We adhere to the one true brace style(OTBS) for brackets. OTBS means that the opening brace for a code block follows its corresponding statement or declaration on the same line.","Bad","Good","The only circumstances where curly brackets may be omitted are when...","An anonymous callback or lambda function is being defined, e.g.","Bad(excessive)","Good(concise)","Handling a (simple) case inside of a switch statement, e.g."]},{"l":"Commas","p":["Unless the file in question is of JSON format, we should use trailing commas wherever possible in the code. In short trailing commas follow the last item in a larger array, despite not having a following item. The reason for this is to make code more editable when we need to move, add, or remove data from said array.","Bad","Good","⚠️ JSON does NOT support trailing commas; only ES5+ code."]},{"l":"Quotes","p":["We use single quotes throughout the codebase.","Bad","Good","We use double quotes only in the following places:","JSON metadata ( NOT supported)","Rust source code ( NOT syntactical)","HTML elements attributes (purely stylistic as single quotes are supported here)"]},{"l":"Semicolons","p":["We are choosing to NOT use semicolons anywhere in the code (unless it is SCSS/CSS code as it is hard-requirement of the syntax)."]},{"l":"Spacing","p":["Spacings are another consideration to make when writing clean code.","They are used in the following places:","After a comment","Bad","Good","Before and after parentheses for if statements","Before and after parentheses for for loops","Before and after parentheses for switch statements","Inside import statements","Inside object definitions","⚠️ Do NOT use tabs for indentation; use spaces instead."]}],[{"l":"Imports"},{"l":"Path Aliases","p":["Path aliases are useful for avoiding long relative import paths and improving the readability of our import statements.","We use the following aliases throughout the entire application:","@core","Contents: code components used in core functionality of the app, e.g. routing, internationalization (i18n), notifications","Location: packages/shared/lib/core/","@common","Contents: code components used commonly throughout the application, e.g. functionality for sending transactions, stores for a profile","Location: packages/shared/lib/common/","@components","Contents: re-usable Svelte UI components used inside of the route components, e.g. buttons, text, popups","Location: packages/shared/components/","Bad","Good"]},{"l":"Order","p":["With clean and easy to read import statements you can quickly see the dependencies of the current code. Make sure you apply following good practices for import statements:","There are no unused imports","Each import group must be separated by a blank line","An import group's import statements must be sorted alphabetically according to their path alias","An import statement's individual imports must be sorted alphabetically according to their variable name","All import groups must adhere to this order:","Svelte library modules (e.g. import { get } from 'svelte/store')","Third-party imports (e.g. import { Converter } from '@iota/client')","Svelte UI components (e.g. import { Button, Text } from '@components')","TypeScript core modules (e.g. import { setRoute } from @core/router)","TypeScript common modules (e.g. import { isStrongholdLocked } from '@common/stronghold/stores')","ℹ️ To help enforce this import strategy, we should look at something like eslint-plugin-import.","Bad","Good"]}],[{"l":"Internationalization","p":["Internationalization refers to designing a product in such a way that it can easily be localized (i.e. localization) into a target language. We currently use the svelte-i18n library to handle this functionality.","⚠️ Localization should be used only when dealing with user-facing text; if the user is not intended to see a message or error, then it does NOT need to be localized."]},{"l":"Usage","p":["It is quite easy to use svelte-i18n once it has been configured and initialized. We simply import the localize(...) function, which allows us to create any localization as long as there is an entry for it in a corresponding {language}.json file.","If the provided path for the locale data does NOT exist, the text will default to English. In the case that the English also does NOT exist, an undefined value will be returned."]},{"l":"International Components for Unicode","p":["As is the norm for internationalization functionality, we adhere to the widely used ICU(International Components for Unicode) message format for creating better adapted localizations. With it, we can...","Create translations with no dynamic data","Create translations with simple dynamic data","Create translations with dynamic amounts","Create translations with multiple conditions","⚠️ Punctuation may or may NOT be used in a locale entry; if relevant, see similar texts to determine if you should use punctuation (e.g. setting description text does NOT use punctuation).","ℹ️ Although these four usages cover our needs well, there are a few more available functionalities specifically surrounding numbers, dates, and times (see here)."]}],[{"l":"Modules"},{"l":"Organization","p":["Modules are the heart of our TypeScript library; they house the various types of code components we use, namely:","actions- higher-level functions that deal with state in some way","api- wrapper functions for wallet.rs NodeJS bindings","constants- values that are defined at compile time","enums- variants of a type grouped together","helpers- helper functions to be used inside of a module (opposite of utils); they MUST NOT be exported in the module's root barrel file","interfaces- object type definitions","stores- Svelte store objects","tests- module unit tests","types- non-object type definitions","utils- utility functions to be used outside of a module (opposite of helpers)","The following is a typical module structure:"]},{"l":"Barrels","p":["A barrel is an intermediary module that rolls up exports from other files and re-exports them. They are the index.(ts|js) files that live within modules.","The functions must be barrel-exported exported within the index.ts file.","Then they can be used within a UI component or another library file."]},{"l":"Constants","p":["Constants are never-changing values that can be used throughout the entire application (i.e. Svelte UI components and other library files). For a variable to be a constant, it must be evaluated at compile-time rather than runtime.","Bad","Good"]},{"l":"Enumerations","p":["Enumerations are objects that define one or more variants of a certain type.","Defining an enumeration","Handling different enum cases"]},{"l":"Functions","p":["Functions are callable objects that perform some type of operation; they are the building blocks of our application. As such, we have different ways that we use them.","There are some general considerations we should all keep in mind when writing functions:","They should be small and contained. When functions have lots of code that is doing many different things, it is hard to navigate and reason about, ultimately making it hard to debug problems or add new features. It is most likely best that the function be refactored into multiple smaller functions within a larger one.","They should contain little-to-no side-effects. These also make code difficult to debug, extend or test, simply because you cannot be sure that a function did only what it said it was going to do. We should apply a more functional-style of programming, the idea being mainly that functions simply (and deterministically) return outputs as a result of some input (i.e. pure functions)."]},{"l":"Regular Functions","p":["These are the most common type of function that we write. They are used in Svelte components, library files, and other places in our applcation.","They have the following rules:","All regular functions must be declared with the function keyword","All regular function signatures must be explicitly typed","Bad","Good"]},{"l":"Anonymous Functions","p":["These are small, unnamed functions that we typically use as callbacks, lambdas, etc.","They have the following rules:","All anonymous functions should be in the ES6 arrow-style syntax; do NOT use the function keyword*","Any anonymous function may be explicitly typed (usually if a type is a non-primitive, e.g. NOT string, number, boolean, etc.)","* The exception to this is when you pass a regular function to a higher-order function.","Bad","Good"]},{"l":"Wrapper Functions","p":["These are the functions that internally access the api object, which contains the API methods for wallet.rs.","They have the following rules:","All wrapper functions must be declared with the function keyword","All wrapper functions must be explicitly typed","All wrapper functions must return a Promise-based type","All wrapper functions must allow for optional callbacks (e.g. onSuccess, onError)","All wrapper functions must be free of side-effects","Bad","Good","ℹ Responses are validated in the onMessage callback via the Validator class."]},{"l":"Interfaces","p":["Interfaces are definitions of a complex object-based type. It may contain fields, functions, or both of these.","For example, we can define a INode interface that describes the properties of a node.","❌ Interfaces should NOT be used to define a data type; instead use the type keyword."]},{"l":"Tests","p":["Tests are files containing one or more unit tests for functions in its corresponding source code file. The tests within a module form a test suite. It is worth noting that if the filename is the-file.ts then its test should be named the-file.test.ts.","ℹ️ Please refer to the testing guide for more info on setting up and running tests."]},{"l":"Writing","p":["Most of the test files should have a structure like this:"]},{"l":"Mocking","p":["Mocks are files that imitate objects or functionality for the sake of testing something. There may be different requirements per whatever it is that is being mocked or will be using the mock, so they may not necessarily all look the same.","To use a mock, simply import it at the beginning of a test file."]},{"l":"Types","p":["Types are definitions of non-object data types, e.g. boolean, number, and string.","ℹ️ It is good practice to explicitly define types for data even if it is simply a number or string. The largest benefit is that if the type were to change at a later point it would be much easier to implement as we would only need to change the defintion rather than all the places where it's used."]}],[{"l":"Naming","p":["Naming is perhaps one of the most important skills for writing clean code. Upon first read, a name should indicate to developers the following things:","Why the code exists?","What is the purpose of the code?","How is the code used?"]},{"l":"General","p":["The following are some general rules about code naming that we follow:","They must be meaningful","Bad","Good","They must be pronounceable","They must NOT be mental mappings","They must NOT add unneeded context"]},{"l":"Files"},{"l":"TypeScript","p":["All TypeScript filenames are in kebab-case, e.g. deep-link-handler.ts. Some filenames may include an optional file type specifier, e.g. deep-link.store.ts."]},{"l":"Svelte","p":["Svelte component names / filenames use the following conventions:","Must be written in PascalCase","Must be suffixed with the component's type, e.g. LedgerTransactionPopup since it is a popup component (this applies to all component types, i.e. routers, views, inputs, buttons, modals, etc.)"]},{"l":"Acronyms","p":["When a variable name contains an acronym, the first letter must be uppercase and the rest lowercase. This convention creates more readable names particularly in the circumstances where another word follows the acronym.","Bad","Good"]},{"l":"Code"},{"l":"Booleans","p":["All objects, functions, stores, i.e. code components of boolean type must be prefixed with being verbs (e.g. \"is\", \"are\", \"has\", \"will\", \"can\", \"should\", \"must\")","Bad","Good","ℹ️ This also pertains to any functions that are of boolean type; isStrongholdLocked() is more self-documenting than strongholdLocked().","All booleans must use positive names"]},{"l":"Constants","p":["All constants must be in SCREAMING_SNAKE_CASE","Bad","Good"]},{"l":"Enumerations","p":["All enum and enum variant names must be in PascalCase","Bad","Good","All enum names must be singular"]},{"l":"Functions","p":["All function names must be in camelCase","Bad","Good","User action handlers must start with on and should end in Click. They mustn’t end in Click when the user action can be triggered by pressing enter button as well.",". Bad","Handlers that aren’t directly triggered by user actions must start with handle"]},{"l":"Interfaces","p":["All interface names must be in PascalCase preceded with an I","Bad","Good"]},{"l":"Types","p":["All type names must be in PascalCase","Bad","Good"]}],[{"l":"Environment Setup","p":["Welcome to the Firefly environment setup guide! Here you will find all of the information regarding how we setup our various development environments."]},{"l":"Dependencies","p":["The following must be installed on all platforms:","Node.js( 16.14.1)","Yarn( 1.22.17)","Rust(LTS)"]},{"l":"MacOS","p":["Xcode Command Line Tools"]},{"l":"Linux","p":["Snapcraft( sudo snap install snapcraft --classic)","Multipass( sudo snap install multipass) or LXD( snap install lxd) are necessary for Snap compilation (to bypass this requirement and build on the host, set SNAP_DESTRUCTIVE_MODE=true)","build-essential","clang(on some older distros, you may need to add LLVM APT repos)","libsecret(Debian/Ubuntu: libsecret-1-dev, Red Hat: libsecret-devel, Arch Linux: libsecret)","libssl(Debian/Ubuntu: libssl-dev, Red Hat: openssl-devel, Arch Linux: openssl)","libusb(Debian/Ubuntu: libusb-1.0-0-dev)","libudev(Debian/Ubuntu: libudev-dev)","gnome-keyring, keepassxc, or another secrets manager that implements the freedesktop.org Secrets API"]},{"l":"Windows","p":["It is highly recommended to use Chocolatey as a package manager for Windows. There are a few dependencies that Chocolatey handles smoothly, which otherwise are often troublesome to install and configure. Read installation steps here.","PowerShell in administrator mode is recommended for the following steps.","Install dependencies for wallet.rs:","ℹ️ llvm can also be downloaded and installed with snapshot builds.","Install and configure dependencies for Windows:","ℹ️ Alternatively, you can download Microsoft C++ Build Tools. You must check boxes for \"Node.js development\" and \"Desktop development with C++\" within the Visual Studio Installer(use the 2019 version).","Add environment variable definitions in ~/.bash_profile or ~/.bashrc:"]}],[{"l":"Desktop","p":["Be sure to follow the base environment setup here!"]},{"l":"Build","p":["Install yarn dependencies:","Build the desktop app:"]},{"l":"Development","p":["Start the development server:"]},{"l":"Production","p":["Change platform as necessary ( win, mac, and linux):","MacOS users must set an environment variable in order to skip notarization:","If Sentry bug reporting needs to be enabled for a local production build, you must modify the packages.json file within packages/desktop/:"]},{"l":"Firefly Snap","p":["To run the Firefly snap properly on Linux, you may need to run the following commands:"]}],[{"l":"Ledger"},{"l":"Hardware","p":["Most of the time, the Ledger hardware devices work quite smoothly when connecting them to your computer."]},{"l":"Setup","p":["For MacOS and Windows systems, the Ledger hardware devices should work smoothly out of the box. If not refer to the troubleshooting section just below.","If you are using a Linux-based system, please be sure that the udev rules are setup properly:"]},{"l":"Troubleshooting","p":["If you are experiencing connection problems with the Ledger device, it is worth trying a few things:","Run the application as administrator (Windows)","Enable full disk access (MacOS)","Try a different USB cable or USB port (the originally packaged cable is best)","Turn off any Anti-virus software or VPNs"]},{"l":"Simulator","p":["The public repository for the IOTA Ledger app lives here. This can be used for...","Running a Ledger Nano S or X hardware simulator","Compiling and loading the app onto a Ledger Nano S","Additionaly, there is a legacy app, which is useful to test migrations. It lives here."]},{"l":"Installing","p":["It is first necessary to install Docker (please see instructions). Alternatively, you can use these commands:"]},{"l":"Cloning","p":["Next, clone the IOTA Ledger app repository:"]},{"l":"Legacy App","p":["In case of the Legacy app clone the following repository and check out the correct branch:","information_source: Pick a mnemonic from this spreadsheet and replace in app-iota-legacy/run_simulator.sh#64 after --seed (note the account index corresponds to the ledger index). Write your used seeds and ledger indexes here: https://hackmd.io/5MQxPS1jT6Cymtmpe6Sq_g?view If we run out of seeds, we have to ping Thomas to restart the network (and the used seeds should be cleaned up in the hackmd)"]},{"i":"update--run-firefly","l":"Update & Run Firefly","p":["Change the following lines to use the simulator:","Under desktop/electron/lib/Ledger.js to await this.iota.setActiveSeed(`44'/4218'/${508396330 + index}'/${page}'`, security || 2)","Under desktop/electron/lib/Ledger.js to const USE_SIMULATOR = true","For using the simulator with migrations, change the following lines as well.","Under shared/lib/migration.ts to export const MIGRATION_NODES = ['https://api-legacy.migrator.h.potonet.if4testing.rocks']","Under shared/lib/migration.ts to return ['https://api.migrator.h.potonet.if4testing.rocks'])","Under shared/lib/migration.ts to export const ledgerSimulator = true","Rebuild desktop to apply the changes yarn build yarn start"]},{"l":"Building","p":["Once cloned, change directories, initialize Git submodules, and run the build script."]},{"l":"Running","p":["After the Docker container is built, the simulator can be run with the following command:","The -m argument is used to specify between the Ledger Nano S and Nano X (default is nanos).","After running, the simulator listens on port 9999 and can be used without restrictions with the ledger-iota.rs library.","ℹ️ When needing to change the mnemonic phrase used for the simulator, please adjust the line here after the --seed argument.","ℹ️ Only one simulator can be run at a time."]},{"l":"Loading","p":["To compile and load the IOTA app on a real Ledger Nano S device, please use the following command:"]}],[{"l":"Tools"},{"l":"Gitify"},{"i":"linting--formatting","l":"Linting & Formatting","p":["We use Prettier and ESLint to handle the TS/JS code and rustfmt for Rust. With the exception of a few files and directories, all of the code within the Firefly repository is run through a linting process to ensure cleanliness and consistency in terms of format, style, syntax, and more. This process happens both locally in a pre-commit Git hook (via Husky) as well as in a continuous integration workflow (see ci.lint.yml)."]},{"i":"tsjs","l":"TS/JS","p":["All of the formatting and linting commands can be run from the root directory.","With formatting there are two options to either overwrite files with fixes or just simply check them for correctness:","For linting there are three options to either check the files, check the files in debug mode, or fix and overwrite the files:","ℹ️ Svelte component files (*.svelte) are checked in addition to regular *.ts source code files."]},{"l":"Retype Documentation","p":["Retype makes it incredibly easy to manage documentation. Simply use the following command from the root directory:"]}],[{"l":"Git","p":["Welcome to the Firefly Git guide! Here you will find all of the information regarding how we create branches, write commits, and organize pull requests."]}],[{"l":"Branches","p":["Branch names must follow a certain structure, which is branch-prefix/branch-name. The branch-prefix corresponds to one of the conventional commit types defined above and the branch name is a concise but informative name representing your changes, e.g. feat/your-cool-feature and chore/new-doc. PR titles are based off of the branch name, so for the examples just used they should be\"feat: Your cool feature\" and \"chore: New doc\"."]},{"l":"Protected Branches","p":["The Firefly team develops code and pushes PRs on certain protected branches. The following three branches are protected:","main: contains the code for Firefly Desktop v1.","develop: contains the code for Firefly Shimmer Desktop"]}],[{"l":"Commits","p":["We use Conventional Commits, so that commit messages are clean and concise. They should follow a consistent structure, being written in present-tense and using the prefixes below:","chore: modifies documentation, cleaning dependencies, other housekeeping-like tasks","ci: creates or changes an existing continuous integration workflow (checkout ci.*.yml files in firefly/.github/workflows/)","feat: introduces a new feature or enhancement of an existing feature","fix: fixes or patches a bug in app functionality","refactor: improvements made to existing code","style: adjusts component styling or UI-only changes","test: changes made only to unit or integration tests","An example might be: feat: Add conversion function for IOTA to fiat currency","The granularity of the commits are ultimately up to you, however we prefer keeping the number of commits lower if possible. The commits are squashed in the end as a change-log / summary of the PR, so do not worry too much."]}],[{"l":"Pull Requests"},{"l":"Creating"},{"l":"When to create a Pull Request","p":["You can create a PR at any time for an existing issue. If the work is not yet in a position to be reviewed then ensure that you create the PR as a draft.","A PR should have exactly one concern (i.e. a feature or a bug). A PR that addresses more than one concern should ideally be split into multiple PRs."]},{"l":"What information to add to the Pull Request","p":["When creating the PR, you will be presented with our current template; it is advisable to fill this template in as detailed as possible, and to the best of your ability. This will allow for a smoother review process, and high probability of your branch being merged.","You should also assign the PR to yourself, add the appropriate labels, link any relevant issues to be closed and if known, request a review of a maintainer."]},{"l":"How to format a Pull Request","p":["It is important to keep the formatting of PRs clean and consistent. In addition to generally following the template, we also use the following rules:","PR titles must be in the format type: the title of the PR.","All words must be lowercase except proper nouns (e.g. \"Electron\", \"Stronghold\") and acronyms (e.g. \"API\").","All code or package names should be formatted as inline code. This is best for things like dependencies as specific variable names are subject to change.","Instructional text (like this) in the template should be removed in PR descriptions."]},{"l":"What labels to use","p":["Please ensure all PRs have a type label, additional labels can be added where deemed appropriate."]},{"l":"Type Labels","p":["feat: Introduces a new feature","enhancement: Enhancement of an existing feature","refactor: Improvements made to existing code","chore: Modifies documentation, cleaning dependencies, or other housekeeping-like tasks","fix: Bug, error, or failure that has been fixed"]},{"l":"Status Labels","p":["do not merge: Do not merge into any working branches"]},{"l":"Reviewing"},{"l":"Requesting a review","p":["Before requesting a review please make sure:","You have completed the task defined in the issue.","If you've added code that should be tested, add tests.","Ensure the test suite passes.","Make sure your code lints.","A PR should have exactly one concern (i.e. one feature or one bug).","All code should follow the coding guide.","Once your PR fulfils the above criteria, you are free to request a review from one of the maintainers."]},{"l":"Completing a review","p":["There are no limitations on who can review a PR, the more eyes on the code the better. All maintainers, Firefly developers and contributors are encouraged to review as many PRs as possible, as well as community members.","At a minimum, it is advised to do the following during a review:","Read the lined issues and PR description to get context for the review","Pull the branch to your local machine and build the application","Manually test the application, focusing on any new features or fixes that have been added","Review the code that has been added or changed","Add feedback in the form of comments, utilising the GitHub review process where possible","You may also want to:","Speak to the author, and walk through the code together","Run tests and linting checks locally (although these are done in GitHub anyway)","Suggest changes to be made by the author","Commit your own small changes if you have the time","⚠️ Sometimes dependency changes within PRs can cause painfully long build times, which then impedes the review process. It is strongly recommended to have a separate repository clone simply for reviewing PRs to ensure that you can continue doing your own work easily."]},{"l":"Merging"},{"l":"Merge Conditions","p":["Conditions for PRs to be merged are dependent on the target branch."]},{"l":"Develop Branch","p":["Before a PR can be merged into the develop branch, it must satisfy the following conditions:","At least one approval review","Zero unresolved comments","Signed commits","No merge conflicts with the target branch","Status checks:","Format and linting tests pass on Rust and JS/TS files","Unit tests pass","If introducing a dependency then Snyk tests pass*","* If your PR is based off of a forked repository, there is no way to test the Snyk continuous integration workflow as it needs an API key. Once your PR has been approved, you must create an intermediary branch on the main repository titled snyk/your-branch-here so that the checks can be performed. Once that passes, then your branch may finally be merged into develop."]},{"l":"Main Branch","p":["Before a PR can be merged into the main branch, it must satisfy the following conditions:","At least one approval review","Zero unresolved comments","Signed commits","No merge conflicts with the target branch","Status checks:","Format and linting tests pass on Rust and JS/TS files","Unit tests pass","Snyk tests pass"]},{"l":"Merge Method","p":["To merge our PRs we are using the Squash and merge option in GitHub.","When you select the Squash and merge option on a pull request on GitHub, the pull request's commits are squashed into a single commit. Instead of seeing all of a contributor's individual commits from a topic branch, the commits are combined into one commit and merged into the default branch. Pull requests with squashed commits are merged using the fast-forward option.","To squash and merge pull requests, you must have write permissions in the repository, and the repository must allow squash merging."]}],[{"l":"Developer Tips","p":["Welcome to the Firefly developer tips! Here you will find all sorts of helpful information for general things across the codebase."]},{"l":"Building and Running"},{"l":"Backend","p":["It is likely that you will NOT have to re-compile the backend (NodeJS or Capacitor) bindings, unless you have either changed or modified specific \"bridge\" functions (like this one)."]},{"l":"Desktop"},{"l":"Svelte Components","p":["If simply making changes to Svelte component files, it is not usually required to fully refresh the development instance (it is typically refreshed for you).","In some cases, the changes can cause unrecoverable errors unless you refresh via the developer console. This usually happens when changing imports or adding a new Svelte file."]},{"l":"TypeScript Library","p":["If making changes within the TypeScript library files, it is usually necessary to refresh the development instance via the console so load the changes.","If editing files that are imported within packages/desktop, then it will be necessary to fully rebuild and restart the development instance. In particular, the following files require rebuilding:","shared/lib/core/shell/*.ts","shared/lib/core/validation/*.ts"]},{"l":"Common Processes"},{"l":"Adding an icon","p":["To add a new (SVG-based) icon for use in the application, simply create a new object entry here.","Most entries here simply include width, height, and path properties, however please be sure that whatever icon you are adding contains all of the necessary SVG data to be displayed correctly (e.g. fillRule s, clipRule s, strokeWidth).","If the icon is still not displaying properly, it is likely that it was either exported incorrectly or can be flattened in the design software before being exported."]},{"l":"Adding a setting","p":["There are a few steps to add a settings component to the Settings menu in Firefly:","Add your component to the correct folder under packages/shared/routes/dashboard/settings/views","Add an export statement to the barrel import/export file in the directory of your new component","Add your component to the settings of the file with the same name as the settings (e.g. Advance.svelte for the advanced setting)","Add your route enum to the appropriate settings route in packages/shared/lib/core/router/enums/routes.ts","Add the correct title and additional texts to the view property in packages/shared/locales/en.json for the translations.","Add an appropriate icon to packages/shared/lib/typings/icons.ts"]},{"l":"Adding a Svelte page","p":["There are a few steps besides just creating the component file before it can work in Firefly:","Add an export statement to the barrel import/export file in the directory of your new component","Add the correct route value to the appropriate enum in packages/shared/lib/typings/routes.ts","Add the correct HTML ( Route nested with Page element) in packages/desktop/App.svelte","Change logic as needed in routerNext in packages/shared/lib/router.ts"]},{"l":"Exposing an API endpoint","p":["wallet.rs has an actor interface, which makes it easy to call functions via messages. To expose a new function one needs to add it to the MessageType and ResponseType enums in wallet.rs/src/actor/message.rs and to the handle method inside of impl WalletMessageHandler { in wallet.rs/src/actor/mod.rs. An example can be seen in this commit."]},{"l":"Troubleshooting"},{"l":"Dependencies"},{"i":"backend-1","l":"Backend","p":["Firefly uses wallet.rs in the backend to handle functionality around value-based transfers. See its README for the required dependencies.","Log files are often required to debug wallet.rs issues. They can be found in the following folders:","Windows: %APPDATA%\\Roaming\\Firefly\\logs","MacOS: $HOME/Library/Application\\ Support/Firefly/logs","Linux: ~/.config/Firefly/logs","For developer/alpha/beta builds you have to look for Electron/'Firefly Shimmer - Alpha'/'Firefly Shimmer - Beta' respectively."]},{"i":"desktop-1","l":"Desktop","p":["There may be times when Firefly just won't seem to compile correctly or you're getting an uncommon error while using it. If you get a blank electron application, reloading the electron application (MacOS: Cmd+R, Linux/Windows: Ctrl+R) might solve your issue. Another approach is updating the yarn dependencies:"]},{"l":"Memory Usage","p":["When developing on Firefly, it is possible that your heap runs out of memory. This has to do with the heap space nodeJS allocates (on Linux this is 2048MB). Setting the heap space to 4096MB fixes this issue. Add the following line to your ~/.bashrc file: export NODE_OPTIONS=--max_old_space_size=4096."]},{"i":"walletrs","l":"wallet.rs","p":["To debug what's going on in the backend you can add","in desktop/electron/preload.js after const Wallet = binding. Debug logs will then be added to the wallet.log file in the same location where Firefly or the Electron / Capacitor development instance is installed."]},{"l":"Resetting Firefly"},{"i":"desktop-2","l":"Desktop","p":["If you want to reset Firefly your profiles are stored in the following places on the different OS'es for the official release:","Windows: %APPDATA%\\Roaming\\Firefly\\__storage__/","MacOS: $HOME/Library/Application\\ Support/Firefly/__storage__/","Linux: ~/.config/Firefly/__storage__/","For developer/alpha/beta builds you have to look for Electron/'Firefly Shimmer - Alpha'/'Firefly Shimmer - Beta' respectively."]}],[{"l":"Testing","p":["Welcome to the Firefly testing guide! Here you will find all of the information regarding how we setup and run tests.","ℹ️ Please refer to the test section of the coding conventions guide for more info on writing tests."]},{"l":"Jest","p":["We use Jest for testing mainly business logic* of Firefly, which is mostly TS/JS source code files in the packages/shared/lib directory. It is important that any files or functions added here should have corresponding unit or integration tests.","* Test coverage is low at this point, but we look to increase that soon with an emphasis on more important functionalities (i.e. transactions, migrating, etc.). Additionally we are looking at adding tests for some important Svelte components."]},{"l":"Running Tests","p":["As only business logic is being tested at the moment, running tests can be done quite simply:","To run all tests (still only source code in packages/shared/lib at the moment):","An example of a happy output:"]}],[{"l":"Product Management","p":["Welcome to the Firefly handbook product management! Here you will find all of the information needed for Firefly epics and milestones"]}],[{"l":"Epics","p":["Begoña","Collectibles","Developer Experience","DRI","E0","E1","E12","E14","E15","E2","E3","E4","E7","Governance","ID","Name","Security","Software Quality","Status","Update stronghold to latest","User Experience","V1 Backblog","V2 Backlog"]}],[{"l":"Milestones","p":["Advanced Collectibles features","Begoña","Collectible collections and UX enhancements","Comprehensive Governance Support","Continuously improve developer experience","Continuously improve documentation","Continuously improve security","Continuously improve software quality","Continuously improve user accessibility","Continuously improve user experience","Desktop v1 maintenance mode","Desktop v2 backlog","DRI","E0 - v2 Backlog","E00.M1","E01.M1","E01.M5","E01.M6","E02.M1","E03.M1","E03.M2","E04.M3","E04.M4","E07.M3","E1 - Software Quality","E12 - Collectibles","E12.M4","E12.M5","E14 - Maintenance","E14.M1","E15 - Update stronghold to latest","E15.M1","E15.M2","E2 - Security","E3 - User Experience","E4 - Developer Experience","E7 - Governance","Epic","ID","Increase test coverage to 75%","Make shared package platform-agnostic","Name","Status","Update stronghold on Firefly (desktop v1.x)","Update stronghold on Firefly Shimmer (desktop v2.x)"]}],[{"l":"Standard Operating Procedures","p":["Welcome to the Firefly handbook standard operating procedures! Here you will find all of the information needed for various team processes."]}],[{"l":"Bug Management","p":["Welcome to the Firefly handbook standard operating procedures for bug management! Here you will find all of the information needed for our common bug management practices.","Bug management is a crucial part of software development, as it ensures the quality of the software and maintains a positive user experience. This standard operating procedure (SOP) outlines the bug management process to be followed by the development team."]},{"l":"Identification","p":["The first step in the bug management process is to identify a bug. Bugs can be identified through various means, such as user feedback, automated testing, or manual testing. Once a bug is identified, it should be reported immediately to the development team."]},{"l":"Classification","p":["The next step is to classify the bug based on its severity and priority. Severity is the impact of the bug on the software, while priority is the urgency of fixing the bug. Bugs can be classified into four categories - Critical, High, Medium, and Low."]},{"l":"Documentation","p":["Once the bug is identified and classified, it should be documented in a bug tracking system. The documentation should include the steps to reproduce the bug, the expected behaviour, and the actual behaviour."]},{"l":"Assignment","p":["The bug should then be assigned to a developer based on their expertise and workload. The assigned developer should acknowledge the bug and provide an estimated time to fix it."]},{"l":"Fixing and Testing","p":["The developer should then fix the bug and perform testing to ensure that the bug is resolved. The fixed code should also be reviewed by another developer to ensure that it does not introduce new bugs."]},{"l":"Verification","p":["After the bug is fixed and tested, it should be verified by the tester to ensure that the bug is indeed resolved. The tester should follow the documented steps to reproduce the bug and verify that it no longer occurs."]},{"l":"Closure","p":["Once the bug is verified, it can be closed in the bug tracking system. The closure should include the details of the fix, the verification results, and the date of closure."]},{"l":"Conclusion","p":["Following this SOP ensures that bugs are managed efficiently and effectively, resulting in high-quality software and a positive user experience."]}],[{"i":"sop---bug-triage","l":"SOP - Bug Triage","p":["Bug triage is a process of identifying, categorising, and prioritising the bugs or issues reported by the customers or internal teams. It is important to have a standard operating procedure (SOP) for bug triage to ensure that all reported issues are addressed efficiently and effectively.","The following steps should be followed for bug triage:"]},{"i":"step-1-receiving-the-bug-report","l":"Step 1: Receiving the Bug Report","p":["The first step of bug triage is to receive the bug report. The bug report can be received from various sources such as customers, internal teams, or automated testing tools."]},{"i":"step-2-prioritisation","l":"Step 2: Prioritisation","p":["Once the bug report is received, it should be prioritised based on its severity and impact on the application. The severity of the bug can be categorised into four levels: critical, high, medium, and low. The impact of the bug can be categorised into three levels: high, medium, and low."]},{"i":"step-3-assigning-to-the-right-team","l":"Step 3: Assigning to the Right Team","p":["Once the bug is prioritised, it should be assigned to the right team for resolution. The team should have the necessary skills and expertise to resolve the bug."]},{"i":"step-4-fixing-the-bug","l":"Step 4: Fixing the Bug","p":["The team should investigate the bug, identify the root cause, and fix the bug. Once the bug is fixed, the team should perform regression testing to ensure that the fix does not cause any other issues."]},{"i":"step-5-verification-and-closure","l":"Step 5: Verification and Closure","p":["Once the bug is fixed, it should be verified by the quality assurance team to ensure that the bug is resolved. Once the bug is verified, it should be closed.","Having a standard operating procedure for bug triage ensures that all reported issues are addressed in a timely and efficient manner. It helps in prioritising the bugs based on their severity and impact, assigning them to the right team for resolution, and ensuring that the bugs are fixed and verified before closing them."]}],[{"l":"Triage Rota","p":["The Triage Rota for Bug Management establishes a structured approach to handle reported bugs in the repository and Discord. The Triage Rota operates on a two-week rotation basis. Each rotation will consist of a pair of developers who will be responsible for bug triage."]},{"l":"Scope","p":["The Triage Rota covers the following areas:","Repository: bug reports submitted through github.","Discord: bug reports received via the designated Discord channels."]},{"l":"Responsibilities","p":["The developers assigned to the Triage Rota are responsible for the Bug Triage during their assigned two-week period."]}],[{"l":"Development","p":["Welcome to the Firefly handbook standard operating procedures for development! Here you will find all of the information needed for our common development practices."]}],[{"l":"Documentation"},{"l":"Purpose","p":["This document details the standard operating procedure (SOP) for maintaining and modifying Firefly documentation (handbook and the GitHub wiki)."]},{"l":"Scope","p":["This SOP is applicable to contributors to the Firefly repository, mainly the core Firefly development team."]},{"l":"Responsibilities","p":["All members of the Firefly team are responsible for maintaining documentation, specifically in ensuring its accuracy and relevancy, as we all use this resource and benefit from it being of the highest possible quality."]},{"l":"Processes","p":["Handbook","GitHub Wiki"]},{"l":"Handbook"},{"l":"Releasing a New Firefly Version","p":["Simply change the value for label under branding in Retype config file to the appropriate version."]},{"l":"Updating the Handbook","p":["To make changes to the documentation within this handbook, begin the process by creating a GitHub task specifically for your desired changes. Please use the \"Continuously improve documentation\" milestone when creating the task."]},{"l":"Updating the Code","p":["When making changes to the code, be sure to check whether the comments if the functions, variables, etc. that you're dealing with are up-to-date and accurate. If writing new code that is exported and intended to be used elsewhere, make sure that it is appropriately commented (see the coding conventions on comments).","Every new folder and page must have an icon: icon entry in the top of its corresponding file (see Octicons). Lastly, every new folder must have some sort of text describing what its purpose is and what you'll find when looking in it."]},{"l":"GitHub Wiki","p":["As it is easier to make changes to the wiki, please feel free to do so as you see fit, while taking care to make sure that any documentation changed there that also exists here must be consistent (with this handbook being the source of truth)."]}],[{"l":"Issues"},{"l":"Purpose","p":["This document details the standard operating procedure (SOP) for maintaining issues that have been raised on GitHub; allowing all team members to remain consistent when organising and maintaining the issues backlog."]},{"l":"Scope","p":["This standard operating procedure is only applicable to maintainers of this repository responsible for the issues backlog; and the issues backlog is that which is found on GitHub only."]},{"l":"Responsibilities","p":["All members of the core firefly team are responsible for managing issues. If an issue is assigned to you, then it is your responsibility. For those issues without an assignee, we aim to follow a rota to ensure that someone is always responsible for new issues created. You will find an up to date rota below."]},{"l":"Schedule","p":["The bug management process is followed by 1 maintainer each week, rotating through all full time maintainers of the Firefly team (in alphabetical order), before cycling back to the begining."]},{"l":"Processes","p":["Bug Management","Support Requests"]},{"l":"External Processes","p":["Security Vulnerability Process"]},{"l":"Bug Management","p":["The bug management process is to be followed when a new issue is raised on GitHub that has the label bug report or an existing issue has been given the label bug report."]},{"l":"Overview","p":["The above diagram details the high level overview of the bug management processes:","Assess whether the issue issue is a valid.","Triage the issue.","Schedule the issue to be fixed.","When managing issues please make sure you assign yourself to the issue on GitHub."]},{"l":"Assessment","p":["The assessment process is usually followed as soon as an issue is labeled as bug report or when we have an existing backlog of bug reports that we need to groom. The assessment process is to ensure that we don't need to triage invalid issues. Please use the below flowchart as a guide to process:"]},{"l":"Triaging","p":["Once an issue has been assessed, we can then triage the issue to decide if we should fix the issue or if we just want to acknowledge the issue because we aren't planning to fix it. This should be done as soon as possible, by following the below process:"]},{"l":"Scheduling","p":["If a bug has been triaged and it is agreed that we should fix the issue, then we need to prioritise the fix and schedule this fix. Again this should be done as soon as possible after triaging, and can be done by following the below process:"]},{"l":"Support Requests","p":["TBD"]}],[{"l":"Releases"},{"l":"Purpose","p":["This document details the standard operating procedure (SOP) for managing the releases of the Firefly Application, so that anyone one of the maintainers can correctly create a release."]},{"l":"Scope","p":["This SOP is only applicable to maintainers of this repository, that are responsible for the release process. Currently this SOP only covers Desktop releases for Linux, Mac and Windows."]},{"l":"Responsibilities","p":["Role","Person","Primary Release Manager","@Nicole","Secondary Release Manager","???"]},{"l":"Schedule","p":["Once a month on the last wednesday the regular release process will be initiated.","The milestone release process will happen for larger milestone based releases, or releases of new platforms.","Hotfixes will occur when there is an important fix that needs to be deployed on a currently released version, before the next regular rlease."]},{"l":"Processes","p":["Release Versioning","Regular Releases","Milestone Releases","Hotfix Releases"]},{"l":"External References","p":["(Git Guide) Branches","(Git Guide) Pull Requests"]},{"l":"Release Versioning","p":["We aim to follow a release versioning convention as close to semantic versioning as possible.","Given a version number MAJOR.MINOR.PATCH, increment the:","MAJOR version when you make incompatible API changes,","MINOR version when you add functionality in a backwards compatible manner, and","PATCH version when you make backwards compatible bug fixes.","Additional labels for pre-release and build metadata are available as extensions to the MAJOR.MINOR.PATCH format.","i.e. our versioning will look like: 1.3.4","Where we use the optional channel and build number for pre-releases. 1.3.4-alpha-1 1.3.4-beta-1","In tags and branches, the versioning will also be prefixed with the platform: desktop-1.4.0- branch or production release tag desktop-1.0.0-alpha-1- pre-release tag"]},{"l":"Regular Releases","p":["The regular release process should be followed monthly according to the schedule defined in this SOP. This is to ensure we are providing consistent updates and bug fixes for all platforms.","As a prerequisite to the release process, both the branching strategy and PR management process are to be followed.","For the regular release process we will aim to follow the below sub processes:"]},{"i":"1-pr-freeze--release-branch","l":"1. PR Freeze & Release Branch","p":["When the regular release process is initiated, the first step is to issue a PR freeze (on the develop branch) to all the maintainers. This will be a simple reminder to tell them that no more PRs will be merged into develop after a given time, until the release branch has been created.","This includes all PR regardless of specific target platform, as the code is closely linked for all platforms.","Usually the release branch will be created in a short time afterwards. But, if it is deemed necessary, it can be decided on a release basis that we will postpone the creation of a release branch until an important PR is merged into develop. The PR freeze will remain for non-important PRs, and they can be marked with the donotmerge label as a reminder.","We will then create the release branch with the following branch naming convention release/platform-version; and the PR freeze will be lifted.","Then we will increment the minor version number in the package.json file."]},{"l":"2. Internal Testing","p":["Once the release branch has been created, as a team we can all build the release branch locally, and test all the core functionality of the application. Testing of additional functionality will be based, on what features have be added or changed in this version.","This will usually last between half a day and 2 days. Any updates can be opened as PRs directly on the release branch (this is because we don't want to prevent changes to develop affecting the release). When we are happy that the application passes our testings criteria we can move on to the next steps."]},{"i":"3-security-audit-optional","l":"3. Security Audit (Optional)","p":["For each release we will decide if and what parts of the application will need to go through the security audit process. This process will be done in parallel to the beta release. If a security audit is deemed necessary, production release will be dependent on the successful completion of said audit."]},{"l":"4. Beta Testing","p":["In parallel or in absence of the security audit, we will begin beta testing the next releases. This is will be a public version of the application, that will have the beta release flag enabled."]},{"l":"A. Release","p":["First we create a release, by tagging the latest commit on the release branch and pushing it to the GH repository. The tag should be created with the following naming convention platform-version-beta-build no; so that the correct workflow is used to create the release builds.","Once the tag is pushed, GH should build the application for the correct platform and release channel i.e. release channel being beta in this instance. And then create a draft GH release with the artifacts.","The release manager, can then edit the release in GH with the change log and beta testing instructions. Followed by, publishing the GH release (ensuring the pre-release option is checked) and creating an entry in the GH announcements discussion."]},{"l":"B. Testing","p":["After a beta release has been published, we now need to communicate the release to the public by posting an announcement and changelog in:","Discord #firefly-beta-testing thread","Discord #tech-announcments channel","Beta testing instructions will be referenced in the announcement and these will be defined in the release description. In short, the public will be encouraged to test the application and new features using a developer profile and connected to the respective devnet. The testers can then discuss issues directly in the firefly beta testing thread, or in the release announcement on the GH wiki, before making a bug report in GH if needed."]},{"l":"C. Fixes","p":["If fixes are needed berfore a release, they can be created as PRs targeting the release branch. If there are fixes that we would like to be retested, we can create a new beta release by going back to step A and incrementing the build number each time."]},{"l":"5. Tag and Release","p":["After sufficient beta testing and fixes have been merged into the release branch. We may then release the application as production ready. This involves:","Creating a tag on the latest stable commit in the release branch with the following naming convention platform-version and pushing to the GH repo","The production build automatically starts using GH action when the tag is pushed","Once the production build is finished a draft release is generated in GH","This release can be edited to include the complete, human readable change log","When ready this GH release can be published and an entry to the announcement channel on GH discussions should be generated","The website will automatically pickup the GH release","Once published on GH and the website, we can initiate the action to upload to S3, where the wallet automatically picks up the new release","After the release has been published in three areas, we can swiftly announce the new version in:","slack channel TBD","Discord #firefly-discussion channel","Discord #tech-announcements channel","Optionally, twitter accounts can share this announcement too"]},{"l":"6. Merging Release Branch","p":["After the application has been released we can then merge the release branch into both main and develop branch to ensure they have the latest updates.","Do not use squash and merge at this point as we will loose the commit history used for the changelog","Do not delete the release branch, as it will be used as the base for hotfixes in the future"]},{"l":"Milestone Releases","p":["The milestone release process is should be followed for large milestones, where we have been using a milestone branch, as opposed to creating PRs directly onto the develop branch.","As a prerequisite to the release process, both the branching strategy and PR management process are to be followed.","For the milestone release process we will aim to follow the below sub processes:"]},{"l":"1. Internal Testing","p":["Once the majority of tasks have been completed for a specific milestone, as a team we can all build the milestone branch locally, and test all the core functionality of the application, as well as testing all the additional features and functionality that is included in the milestone.","This will usually last between a day and 1 week. Any updates can be opened as PRs directly on the milestone branch. When we are happy that the application passes our testings criteria we can move on to the next steps."]},{"l":"2. Alpha Testing","p":["With the milestone releases, we will utilise a closed testing group so that we can gather wider feedback and testing capabilities before the feature is released to the public. This will be a private build of the application using the alpha release flag."]},{"i":"a-release-1","l":"A. Release","p":["First we create a release, by tagging the latest commit on the milestone branch and pushing it to the GH repository. The tag should be created with the following naming convention platform-version-alpha-build no; so that the correct workflow is used to create the release builds.","Once the tag is pushed, GH should build the application for the correct platform and release channel i.e. release channel being alpha in this instance. And then create a draft GH release with the artifacts.","The release manager, can then edit the release in GH with the change log and beta testing instructions. Followed by, publishing the GH release (ensuring the pre-release option is checked) and creating an entry in the GH announcements discussion."]},{"i":"b-testing-1","l":"B. Testing","p":["After a beta release has been published, we now need to communicate the release to the closed testing group by posting an announcement and changelog in:","Discord #firefly-alpha-testing thread","Alpha testing instructions will be referenced in the announcement and these will be defined in the release description. In short, the closed testing group will be encouraged to test the application and new features using a developer profile and connected to the respective devnet. The testers can then discuss issues directly in the firefly alpha testing thread, or in the release announcement on the GH wiki, before making a bug report in a dedicated online document."]},{"i":"c-fixes-1","l":"C. Fixes","p":["If fixes are needed berfore a beta release, they can be created as PRs targeting the milestone branch. If there are fixes that we would like to be retested, we can create a new alpha release by going back to step A and incrementing the build number each time."]},{"i":"3-merging-milestone-branch--create-release-branch","l":"3. Merging Milestone Branch & Create Release Branch","p":["After sufficient internal testing and alpha testing, a PR containing the milestone branch can then can then be reviewed on GH and follow the normal PR process; except we should have a minimum of two approvers to merge the milestone into the release branch as it will contain a large amount of changes.","Once the approced and merged is in the develop branch, we can create a release branch following the naming conventions defined in the branching strategy."]},{"i":"4-security-audit-optional","l":"4. Security Audit (Optional)","p":["For each release we will decide if and what parts of the application will need to go through the security audit process. This process will be done in parallel to the beta release. If a security audit is deemed necessary, production release will be dependent on the successful completion of said audit."]},{"i":"5-beta-testing-optional","l":"5. Beta Testing (Optional)","p":["In parallel or in absence of the security audit, we can begin beta testing the next releases. This is will be a public version of the application, that will have the beta release flag enabled."]},{"i":"a-release-2","l":"A. Release","p":["First we create a release, by tagging the latest commit on the release branch and pushing it to the GH repository. The tag should be created with the following naming convention platform-version-beta-build no; so that the correct workflow is used to create the release builds.","Once the tag is pushed, GH should build the application for the correct platform and release channel i.e. release channel being beta in this instance. And then create a draft GH release with the artifacts.","The release manager, can then edit the release in GH with the change log and beta testing instructions. Followed by, publishing the GH release (ensuring the pre-release option is checked) and creating an entry in the GH announcements discussion."]},{"i":"b-testing-2","l":"B. Testing","p":["After a beta release has been published, we now need to communicate the release to the public by posting an announcement and changelog in:","Discord #firefly-beta-testing thread","Discord #tech-announcments channel","Beta testing instructions will be referenced in the announcement and these will be defined in the release description. In short, the public will be encouraged to test the application and new features using a developer profile and connected to the respective devnet. The testers can then discuss issues directly in the firefly beta testing thread, or in the release announcement on the GH wiki, before making a bug report in GH if needed."]},{"i":"c-fixes-2","l":"C. Fixes","p":["If fixes are needed berfore a release, they can be created as PRs targeting the release branch. If there are fixes that we would like to be retested, we can create a new beta release by going back to step A and incrementing the build number each time."]},{"l":"6. Tag and Release","p":["After sufficient beta testing and fixes have been merged into the release branch. We may then release the application as production ready. This involves:","Creating a tag on the latest stable commit in the release branch with the following naming convention platform-version and pushing to the GH repo","The production build automatically starts using GH action when the tag is pushed","Once the production build is finished a draft release is generated in GH","This release can be edited to include the complete, human readable change log","When ready this GH release can be published and an entry to the announcement channel on GH discussions should be generated","The website will automatically pickup the GH release","Once published on GH and the website, we can initiate the action to upload to S3, where the wallet automatically picks up the new release","After the release has been published in three areas, we can swiftly announce the new version in:","slack channel TBD","Discord #firefly-discussion channel","Discord #tech-announcements channel","Optionally, twitter accounts can share this announcement too"]},{"l":"7. Merge Release Branch","p":["After the milestone has been released we can then merge the release branch into both main and develop branch to ensure they have the latest updates.","Do not use squash and merge at this point as we will loose the commit history used for the changelog","Do not delete the release branch, as it will be used as the base for hotfixes in the future"]},{"l":"Hotfix Releases","p":["The hotfix release process commences when a maintainer creates a PR with a hotfix targetting a previous release.","A hotfix is any PR that is targeting a previous release directly, and as such should be released after merging into the release branch.","To release a hotfix we will aim to follow the below sub processes."]},{"i":"1-internal-testing-1","l":"1. Internal Testing","p":["Once the the PR is deemed ready for a review, as a team we can all build the hotfix branch locally, and test all the core functionality of the application, as well as hotfix functionality.","This will usually last between half a day and 1 full day. Any updates can be commited directly to the hotfix branch. When we are happy that the application passes our testings criteria we can move on to the next steps."]},{"i":"2-pr-approval--merge-release-branch","l":"2. PR Approval & Merge Release Branch","p":["After sufficient internal testing, the code can then be reviewed on GH and follow the normal PR process; except we should have a minimum of two approvers to merge the hotfix into the release branch as it is going to be released without additional alpha or beta testings."]},{"l":"3. Tag and Release","p":["Once the hotfix has been merged into the release branch; we may then release the application as production ready. This involves:","Creating a tag on the latest stable commit in the release branch with the following naming convention platform-version and pushing to the GH repo","The production build automatically starts using GH action when the tag is pushed","Once the production build is finished a draft release is generated in GH","This release can be edited to include the complete, human readable change log","When ready this GH release can be published and an entry to the announcement channel on GH discussions should be generated","The website will automatically pickup the GH release","Once published on GH and the website, we can initiate the action to upload to S3, where the wallet automatically picks up the new release","After the release has been published in three areas, we can swiftly announce the new version in:","slack channel TBD","Discord #firefly-discussion channel","Discord #tech-announcements channel","Optionally, twitter accounts can share this announcement too"]},{"l":"4. Merge Release Branch","p":["After the hotfix has been released we can then merge the release branch into both main and develop branch to ensure they have the latest updates.","Do not use squash and merge at this point as we will loose the commit history used for the changelog","Do not delete the release branch, as it will be used as the base for hotfixes in the future"]}],[{"l":"Crowdin","p":["We use (Crowdin)[https://crowdin.com/] for localization management."]},{"l":"Process","p":["Merge English translations and trigger “Crowdin” workflow to push strings to translators. There are different translations for develop and main branches.","Ping translators in discord (#firefly-translations). Example:"]}],[{"l":"Specifications","p":["Welcome to the Firefly handbook specifications! Here you will find all of the technical information about our code."]}],[{"l":"Activities","p":["This section describes the Activity History, its generation and internal structure. Due to IOTA's and Shimmers UTXO architecture, there is no 1:1 mapping between transactions and activities. Each output has to classified and has to be combined/hidden/updated in different cases. The main goal is to optimize UX by simplifying the complex UTXO architecture into a transaction based overview."]}],[{"l":"Class Diagram","p":["This document includes the class diagram of all activity types"]}],[{"l":"Generation Flow","p":["This document describes our approach of transforming the list of outputs associated with an account into an activity history. The following approach and the related architectural design choices have its limitations. The corresponding sections address these."]},{"l":"Activity Initialization","p":["After syncing all of the accounts, the accounts contains outgoing transactions and incoming outputs. These objects are highly nested and too complex for a non-technical user to understand and draw simple conclusions from them (e.g. Who was the sender/receiver? Do I have to claim that first?).","The first step is to transform both transactions and outputs into activities. Transactions contain the most information, so these have the highest priority for the activity overview."]},{"l":"Transactions","p":["With transactions we can build complete activities.","Currently we only have outgoing transactions. Soon we will also get transactions attached to the incoming outputs, allowing us to add more information to these activities as well.","Important: They are guaranteed to persist in wallet.rs, but not on the nodes. This means we can lose the information and therefore need a fallback option."]},{"l":"Outputs","p":["If transactions were pruned on the nodes, and we restore a profile, we cannot access them anymore. For this case, we fallback on creating activities from pure outputs. These contain no information about its origin, so there's no way to compute the sender for incoming ones.","Additionally we don't have outputs generated by transactions initialized by us."]},{"l":"Activity Post-Processing","p":["The previous step initialized all activities. But activities on their own are missing some important UX properties, because they can only be deduced by comparing them with each other. Depending on the result of such a comparison, some activities get updated, while others get hidden to not confuse the user.","Currently we have 2 post-processing steps, but this list can be expanded if new requirements arise."]},{"l":"Claimed Activity","p":["Activities can be claimable because of different reasons: a contained storage deposit, expiration date, etc. Claiming one always results in a new transaction, consuming the claimable activity and resulting in an output to the corresponding account."]},{"l":"Incoming","p":["We can compute incoming, claimed activities because we have all incoming outputs (which contain the claimable activities) and outgoing transactions (which includes the claiming activity).","Find Matching Pair: For each async activity A1 another future activity A2 is searched, that contains A1 as an input. If one is found, we have a match.","Result: Claimed activity A1 gets updated, claim status is set to true, claim time and claim id will be updated to the claiming transactions infos. Claiming activity A2 gets hidden"]},{"l":"Outgoing","p":["Currently not implemented / not possible. We can compute which of the activities result in a claimable activity for the receiver account, but we have no way to check if they consumed it."]},{"l":"Storage Deposit Return","p":["Sending small funds result in a storage deposit. When the receiving account claims the funds, they send a transaction back to the original sender containing that storage deposit return (SDR).","Find Matching Pair: For each activity A1 with a SDR, we narrow the potential SDR activities down by some conditions (currently: Candidate happened after A1. Candidates amount needs to be the same as the storage deposit). These candidates need to be checked around 2 corners: If the input of the input of the candidate is A1, we have a match.","Result: Activity containing the storage deposit gets updated, storage deposit gets crossed out in detailpopup. Return activity gets hidden"]},{"l":"Preparation for Overview","p":["After creating and post-processing the activities, they are being prepared for the UI. Depending on the selected account, inserted search term or active filter, a corresponding subset of all activities is displayed, after being grouped together by the transaction time."]}],[{"l":"Onboarding","p":["Onboarding refers to the process of creating a new profile and sometimes configuring general application settings."]},{"l":"Sections","p":["This part of the app consists of different sub-sections:","App Setup: Configuration of general application settings, e.g. language, appearance, agreeing to policies (if NOT completed onboarding before)","Network Setup: Choosing the protocol, network, and possibly a custom node to be used by the profile","Profile Setup: Selecting the method in which to create the profile (claim rewards, create new, or recover / restore), the secret manager to use, and lastly choosing a name","Profile Recovery: Recovering or restoring a profile based on a mnemonic phrase, Stronghold backup, or Ledger device (claiming rewards or recovering / restoring profiles ONLY)","Stronghold Setup: Configuring the password for the Stronghold encryption (software profiles ONLY)","Storage Protection Setup: Choosing and configuring the protection method for the profile's local data (currently only PIN)","Ledger Setup: Verifying and / or establishing connection with the Ledger device","Profile Backup: Backing up a mnemonic phrase on paper and / or exporting a Stronghold backup","Shimmer Claiming: Finding and claiming Shimmer rewards"]}],[{"l":"Routing"},{"l":"Routing"},{"l":"Flowchart"}],[{"l":"Shimmer Claiming","p":["Shimmer \"claiming\" refers to the process of transferring SMR tokens from an address used in an UTXO within the genesis snapshot to a new address that is derived using the same seed, but with a different coin_type parameter (IOTA = 4218, Shimmer = 4219)."]},{"l":"Overview","p":["Throughout the app, we have a profileManager object that exposes wallet.rs API methods that allow us to do various things, one of which is creating and managing new accounts. In order to create it, we must pass a coinType when initializing the object so that it knows how exactly to create accounts and generate addresses.","Normally this object is created with coinType = 4219(Shimmer), but we need to use a special one where coinType = 4218(IOTA). The reason is so that we can generate the same Ed25519 addresses that were ultimately used when the IOTA community staked for Shimmer rewards in November 2021. This special object is called the shimmerClaimingProfileManager."]},{"l":"Finding Rewards","p":["It is possible that a user has a high number of accounts, addresses, or both, where they staked his or her IOTA to receive SMR airdrops. This is due to Firefly V1 using new addresses after previous ones were already spent.","Using the shimmerClaimingProfileManager, we must generate addresses and query the nodes to determine regardless of whether funds reside on them. If funds do exist, it means that they have NOT yet been claimed from their respective genesis output."]},{"l":"Claiming Rewards","p":["Once funds are found on a particular set of accounts and their addresses, the user can initiate the claiming process.","Here, we generate a deposit address ( index = 0) with the regular profileManager object, so that the funds will reside on a proper Shimmer-based addresses. Taking that address, we send a transaction to it using the shimmerClaimingProfileManager to sign it, effectively \"claiming\" the funds. This process happens for each account where funds were found."]}],[{"l":"Deep Links","p":["Deep links are special URLs that, when navigated to, open applications rather than a website. In our case we are interested in the user experiences that they enable between websites, applications, platforms, etc. by providing more interoperability.","Firefly has its own deep link scheme, exposing (limited) functionality that is required in some type of user flow. A trivial example would be a user who buys native tokens on Soonaverse and must make a payment transaction to execute the buy order. Clicking on a deep link embedded inside the Soonaverse platform triggers Firefly to open and auto-fill the transaction data as necessary, making it a simple confirm and click job for the user.","Firefly will NEVER automatically execute actions initiated by a deep link; they should ALWAYS require manual confirmation on behalf of the user."]},{"l":"Scheme","p":["The Firefly deep link scheme can be broken down to the following (simple) syntax:","The parameters are as follows:","stage- indicates a specific stage of the app to target, options are:","alpha- the first available version of Firefly containing brand new features","beta- the next available version of Firefly containing new but slightly tested features","shimmer- the Firefly Shimmer version, containing new and well-tested features","context- the part of Firefly that contains the operation, options are:","wallet- managing coins and tokens","collectibles- managing NFTs","governance- managing voting events and proposals","operation- an operation within a specific context (see below for more detail)","param- query parameter(s) relevant for the specified operation","If you wish to target the production version, simply omit this from the prefix:","This deep link scheme is NOT compatible with Firefly V1, as that version of the application is in maintenance mode."]},{"l":"Contexts"},{"l":"Wallet"},{"l":"Send Form","p":["This operation brings the user to the send form popup:","The deep link structure is as follows:","The following parameters are required:","address- the recipient's address where the funds will be sent to","MUST be a Bech32 address; considering support for other address types in the future","amount- the amount of tokens to send in the transaction","MAY contain a decimal so long as it makes sense given the value of the unit param (see below)","The following parameters are optional:","unit- a specified denomination of the token to use, if applicable (default for IOTA is Mi, SMR is SMR)","assetId- the identifier of the asset to send, e.g. 4218(IOTA), 4219(SMR), or a native token ID (default is base token of the network, i.e. IOTA or SMR)","metadata- a string of text to embed as metadata in the transaction","tag- a string to tag the transaction for indexing purposes","Example:","Click me!","Source:"]},{"l":"Send Confirmation","p":["address- the recipient's address where the funds will be sent to","amount- the amount of tokens to send in the transaction","assetId- the identifier of the asset to send, e.g. 4218(IOTA), 4219(SMR), or a native token ID (default is base token of the network, i.e. IOTA or SMR)","Click me!","disableChangeExpiration- prevents the user from being able to change the expiration time of the transaction","disableToggleGift- prevents the user from being able to toggle the option to gift the storage deposit","Example:","giftStorageDeposit- gifts the tokens used in funding the storage deposit for a transaction","MAY contain a decimal so long as it makes sense given the value of the unit param (see below)","metadata- a string of text to embed as metadata in the transaction","MUST be a Bech32 address; considering support for other address types in the future","Source:","surplus- send additional amounts of the base token when transferring native tokens","tag- a string to tag the transaction for indexing purposes","The deep link structure is as follows:","The following parameters are optional:","The following parameters are required:","This operation brings the user to the send confirmation popup:","unit- a specified denomination of the token to use, if applicable (default for IOTA is Mi, SMR is SMR)"]},{"l":"Collectibles","p":["Coming \uD83D\uDD1C"]},{"l":"Governance"},{"l":"Add Proposal","p":["This operation brings the user to the add proposal popup:","The deep link structure is as follows:","The following parameters are required:","eventId- the event ID of the proposal's corresponding participation event in the network","The following parameter(s) are optional:","nodeUrl- the specific node that is tracking the proposal's corresponding participation event","If the node requires authentication (e.g. username and password, JWT), the user will be required to manually enter the information.","Example:","Click me!","Source:"]}],[{"l":"Governance","p":["Governance refers to the feature allowing users to vote on important community-wide decisions along with other operations and functionality to help achieve a smooth user experience.","packages/desktop/features/governance.features.ts contains the feature flag that allows you to disable the tab if necessary."]},{"l":"Definitions","p":["Event- a participation event where a user can vote (or stake) his or her funds; this always assumes a voting event unless specified otherwise","Event phase- an event can be in four different phases:","upcoming- corresponds to \"Announcement\"","commencing- corresponds to \"Voting open\"","holding- corresponds to \"Counting\"","ended- corresponds to \"Closed\"","Governance- rules and processes to make decisions concerning permissionless applications and platforms","Participation- interacting with or taking part in an event, either by voting or staking funds","Proposal- synonymous with voting event, which is an event that contains one or more questions that users can vote on","Vote- participating in a voting event, initially by selecting answers (aka votes) for each question on the proposal's ballot then broadcasting a transaction with appropriately structured metadata (so that it can be tracked by the node(s))","Voting output- a designated output to be used for all voting operations (e.g. increasing or decreasing voting power and voting or unvoting for an event)","Voting power- the amount of votes a user can cast for a proposal, which is based on how much IOTA or SMR he or she has; this MAY or MAY NOT be the same as a user's total balance, it depends on how much they have manually designated as their voting power"]},{"l":"Adding a Proposal","p":["A user first needs to add a proposal to his or her dashboard to be able to vote on it. This can happen in multiple ways:","Firefly automatically registering the proposals that are published on the node(s) specified in the client options","The user manually entering a proposal (aka event) ID and a node URL on which the event was published","The user following a deep link containing a proposal (aka event) ID and a node URL on which the event was published","Firefly regularly polls the given node(s) to update the states of the added proposals, which includes the current vote results.","Users may also remove proposals from their account(s), but only if they are NOT currently voting for the proposal."]},{"l":"Voting on a Proposal"},{"l":"Managing Voting Power","p":["Users must have a non-zero voting power to be able to vote for a proposal. They click the \"Manage voting power\" button from the Governance dashboard to increase or decrease their voting power.","A voting output is equivalent to a basic output that is tagged with the PARTICIPATE keyword. They are designated for voting only and will NOT be used in non-Governance transactions. A user can choose to designate any non-zero amount less than or equal to their available balance to become his or her voting power.","Voting outputs are inconsumable for all transactions, unless the user is...","Increasing or decreasing voting power","Voting or unvoting for a proposal","By consequence, this means that voting power is NOT considered a part of a user's available balance."]},{"l":"Casting a Vote","p":["In order to cast a vote for a proposal, there are two steps:","Select at least one answer for a question on the proposal's ballot","Broadcast a transaction containing the vote(s) as both a tagged data payload (what is tracked by the nodes) and output metadata","If the user is voting for the first time, the data payload and output metadata will be added alongside the existing PARTICIPATE tag, otherwise the answers will be appended to the existing payload and metadata. As a result, users can vote for multiple proposals with the same amount of voting power.","Unvoting for a proposal simply removes the relevant data from the data payload and output metadata."]},{"l":"Resources","p":["RFC-06 (Hornet Participation Plugin)","TIP-0020 (Transaction Payload with TIP-0018 Output Types)","TIP-0023 (Tagged Data Payload)"]}],[{"l":"Library Modules","p":["The library modules are divided into three categories (detailed below), each indicating the purpose, responsibility, and scope of the modules inside."]},{"l":"Core","p":["Core modules contain the baseline logic and functionality to build and run the application."]},{"l":"Modules","p":["account- Manages the accounts of a profile","app- Application configuration, setup, settings, etc.","error- Generic code for building domain-specific errors","i18n- Logic related to internationalization, languages, locales, etc.","ledger- Code related to Ledger Nano profiles and devices","network- Client options and node configuration, protocol settings, etc.","nft- Managing NFTs, e.g. claiming, burning, transferring","profile- General application logic to support profiles","profile-manager- Library-related logic for managing and interacting with profiles","router- Manage application views and flows","stronghold- Code for Stronghold operations, utils, constants, etc. for software profiles","token- Deals with tokens, metadata, conversion rates, registry, etc.","utils- Useful and generic functions, e.g. formatting strings, converting units"]},{"l":"Rules","p":["MAY import code from other core modules","MAY NOT import code from context or auxiliary modules"]},{"l":"Contexts","p":["Context modules contain the logic specific to an area of the application."]},{"i":"modules-1","l":"Modules","p":["collectibles- managing or viewing an account's NFTs","developer- using developer tools to make lives easier","onboarding- creating or restoring a profile or initial app setup","settings- changing configuration of the app, profile, network, etc.","staking- staking tokens to receive more tokens","governance- using tokens to cast votes for community proposals","wallet- sending or receiving coins and tokens, i.e. asset management"]},{"i":"rules-1","l":"Rules","p":["MAY import code from core and auxiliary modules","SHOULD NOT import code from other context modules"]},{"l":"Auxiliary","p":["Auxiliary modules are non-essential pieces of code that help support the application."]},{"i":"modules-2","l":"Modules","p":["deep-link- parsing of deep links","notification- managing notifications (both toast and system)","popup- facilitates opening and closing of a popup","wordlists- lists of the 2,048 words allowed in BIP39 (currently only English)"]},{"i":"rules-2","l":"Rules","p":["MAY NOT import code from context modules","SHOULD NOT import code from other auxiliary modules"]}],[{"l":"Glossary"},{"i":"bitcoin-improvement-proposals-bips","l":"\uD83D\uDD87️ Bitcoin Improvement Proposals (BIPs)","p":["Similar to an IOTA TIP (\"Tangle Improvement Proposal\"), a BIP is a proposed plan for improving or adding functionality to a specific part of the protocol. They are important because they define and iterate on mechanisms, rules, and standards for a compatible DLT's (distributed ledger technology) implementation."]},{"i":"bip32---hierarchical-deterministic-hd-wallet","l":"BIP32 - Hierarchical deterministic (HD) wallet","p":["This proposal acts as a definition for how a wallet should derive encryption keys from any given seed. The hierarchy is described by a BIP32 path, which looks like:","⚠️ Sometimes these values are in hexadecimal format (Ledger users will see this when prompted to confirm newly generated addresses).","m- the binary representation of a seed (e.g. 24-word mnemonic)","purpose'*- a fixed value indicating that (usu. 44' representing BIP44) should be used as a standard","coin_type'*- the particular number of a cryptocurrency token (IOTA is 4218'- see SLIP44)","account'*- the index for an account, of which there are 2,147,483,648 possible values (in Firefly these are the individual \"wallets\" in a single profile)","change- 0' or 1' depending on if the address was generated for moving a transaction's remainder funds ( 1) or is an external address for receiving funds ( 0)","address- the index for an address, of which there are 2,147,483,648 possible values (in Firefly these are the individual addresses per each wallet in a single profile)","* The added apostrophe indicates a hardened derivation at that level, which means that it is not possible to link a public key with its parent or child public keys via the public keys alone. With this mechanism being used at least the account level, the case of an accidental leak of account-specific keys does NOT compromise other accounts or the master (m).","BIP32 is important as without it, you may not necessarily be able to gain access to your funds - you must know which indices the funds reside on to gain access (i.e. you can know which private / public key-pair to generate from the seed). Do not worry though as Firefly sequentially generates new accounts and addresses, which is what allows the balance finder in the settings to more easily find your funds should they be \"lost\"."]},{"i":"bip39---mnemonic-code-key-derivation","l":"BIP39 - Mnemonic code key derivation","p":["This BIP proposes the usage of a generated 12-24 word mnemonic phrase that can be securely converted into a binary seed intended for generating deterministic wallets using BIP32. The major improvement here is that humans can much more easily handle a series of words rather than 0s and 1s, making the storage and recovery of seeds much more friendly.","It consists of two parts: the generation of the mnemonic itself and the conversion into a binary seed. English words are selected from a specially curated list of 2,048 words with an optional passphrase for added security (an empty string is used if empty). The keys are derived through algorithms PBKDF2 and HMAC- SHA512 with a length of 512 bits or 64 bytes."]},{"i":"bip44---multi-account-hierarchy","l":"BIP44 - Multi-account hierarchy","p":["This BIP proposes a definition for the logical hierarchy of deterministic wallets. It allows a user to handle multiple tokens from varying cryptocurrencies with each one having possibilities for millions of accounts each with millions of addresses.","To help understand the technical definition, please read the above description about BIP32 paths. However it's also important to understand how this structure is translated into Firefly:","A profile is at the top-most level of the hierarchy as with Firefly there is one mnemonic per profile","Wallets, also known as \"Accounts\", are three levels lower than the profile / seed (past purpose and coin_type) therefore can only be belonging to a single profile","Addresses are formed on chains from values 0 and 1 on the change level, putting them two levels lower than the account level, however in Firefly we typically only see the receive addresses from the chain when change = 0"]},{"i":"iota-networks","l":"\uD83C\uDF10 IOTA Networks","p":["The IOTA ecosystem contains a variety of networks each with different purposes and use cases."]},{"l":"Mainnet","p":["The mainnet is the primary network within the IOTA ecosystem where tokens holding real value are transferred to and from participants and data is broadcasted across a public network."]},{"l":"Devnet","p":["The devnet, refers to the secondary network within the IOTA ecosystem where tokens of fake value are transacted with, and data is broadcasted publicly across the network."]},{"l":"Testnet","p":["Similar to the devnet, the testnet is a network that until recently was the secondary network for the Chrysalis upgrade. The network still exists and is still being used for testing transactions and data message broadcasting."]},{"l":"Private Tangles","p":["Private tangles are networks that can be setup for use by an individual or even a smart city. The tokens do NOT hold real-world value, and the data messages are broadcasted onto the configured private network."]},{"i":"stronghold","l":"\uD83D\uDD10 Stronghold","p":["Stronghold is an open-source software library developed and maintained by the IOTA Foundation (see stronghold.rs). It deals with the protection of important secrets like the seed of a Firefly profile or the public-private key pairs for accounts (or wallets) within a Firefly profile.","It is designed to be used within other libraries, such as wallet.rs, or even within the provided peer-to-peer (p2p) communication layer for when higher security is needed."]}]]